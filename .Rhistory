cost_complexity = tune(),
tree_depth = tune(),
min_n = tune() #min number of obs in a node
) %>%
set_engine("rpart") %>% #package name rpart , show_engines("decision_tree")
set_mode("classification") #regression/classification
folds = vfold_cv(train, v = 5)
tree_grid = grid_regular(cost_complexity(), tree_depth(),
min_n(), levels = 3) #select 3 values for each
cost_complexity()
tree_depth()
min_n()
# below code runs your code on parallel cores of your cpu
# makes the process faster
doParallel::registerDoParallel()
cost_complexity()
tree_depth()
my_res=tune_grid(
tree_model,
Revenue.Grid~.,
resamples = folds,
grid = tree_grid,
metrics = metric_set(roc_auc), #rmse ,mae for regression
control = control_grid(verbose = TRUE)
)
autoplot(my_res)+theme_light() #roc higher the better
folds = vfold_cv(train, v = 10)
tree_grid = grid_regular(cost_complexity(), tree_depth(),   # run each ot these indvidually to get idea of range
min_n(), levels = 10) #select 3 best values for each of these
my_res=tune_grid(
tree_model,
Revenue.Grid~.,
resamples = folds,
grid = tree_grid,
metrics = metric_set(roc_auc), #rmse ,mae for regression
control = control_grid(verbose = TRUE)
)
autoplot(my_res)+theme_light() #roc higher the better
folds = vfold_cv(train, v = 5)
tree_grid = grid_regular(cost_complexity(), tree_depth(),   # run each ot these indvidually to get idea of range
min_n(), levels = 7) #select 3 best values for each of these
my_res=tune_grid(
tree_model,
Revenue.Grid~.,
resamples = folds,
grid = tree_grid,
metrics = metric_set(roc_auc), #rmse ,mae for regression
control = control_grid(verbose = TRUE)
)
autoplot(my_res)+theme_light() #roc higher the better
fold_metrics=collect_metrics(my_res)
fold_metrics=collect_metrics(my_res)
my_res %>% show_best()
final_tree_fit=tree_model %>%
finalize_model(select_best(my_res)) %>%
fit(Revenue.Grid~.,data=train)
View(final_tree_fit)
# feature importance
final_tree_fit %>%
vip(geom = "col", aesthetics = list(fill = "midnightblue", alpha = 0.8)) +
scale_y_continuous(expand = c(0, 0))
rpart.plot(final_tree_fit$fit)
train_pred=predict(final_tree_fit,new_data = train,type="prob") %>% select(.pred_1)
test_pred=predict(final_tree_fit,new_data = test,type="prob") %>% select(.pred_1)
train.score=train_pred$.pred_1
real=train$Revenue.Grid
rocit = ROCit::rocit(score = train.score,
class = real)
kplot=ROCit::ksplot(rocit,legend=F)
my_cutoff=kplot$`KS Cutoff`
test_hard_class=as.numeric(test_pred>my_cutoff)
rf_model = rand_forest(
mtry = tune(),
trees = tune(),
min_n = tune()
) %>%
set_mode("classification") %>%
set_engine("ranger")
rf_model = rand_forest(
mtry = tune(),
trees = tune(),
min_n = tune()
) %>%
set_mode("classification") %>%
set_engine("ranger")
folds = vfold_cv(train, v = 5)
mtry()
trees()
min_n()
folds = vfold_cv(train, v = 5)
rf_grid = grid_regular(mtry(c(5,25)), trees(c(100,500)),
min_n(c(2,10)),levels = 3)
my_res=tune_grid(
rf_model,
Revenue.Grid~.,
resamples = folds,
grid = rf_grid,
metrics = metric_set(roc_auc),
control = control_grid(verbose = TRUE)
)
final_rf_fit=rf_model %>%
set_engine("ranger",importance='permutation') %>%
finalize_model(select_best(my_res,"roc_auc")) %>%
fit(Revenue.Grid~.,data=train)
rf_model = rand_forest(
mtry = tune(),
trees = tune(),
min_n = tune()
) %>%
set_mode("classification") %>%
set_engine("ranger")
folds = vfold_cv(train, v = 5)
rf_grid = grid_regular(mtry(c(5,25)), trees(c(100,500)),
min_n(c(2,10)),levels = 3)
my_res=tune_grid(
rf_model,
Revenue.Grid~.,
resamples = folds,
grid = rf_grid,
metrics = metric_set(roc_auc),
control = control_grid(verbose = TRUE)
)
install.packages("ranger")
my_res=tune_grid(
rf_model,
Revenue.Grid~.,
resamples = folds,
grid = rf_grid,
metrics = metric_set(roc_auc),
control = control_grid(verbose = TRUE)
)
autoplot(my_res)+theme_light()
fold_metrics=collect_metrics(my_res)
my_res %>% show_best()
final_rf_fit=rf_model %>%
set_engine("ranger",importance='permutation') %>%
finalize_model(select_best(my_res,"roc_auc")) %>%
fit(Revenue.Grid~.,data=train)
final_rf_fit %>%
vip(geom = "col", aesthetics = list(fill = "midnightblue", alpha = 0.8)) +
scale_y_continuous(expand = c(0, 0))
train_pred=predict(final_rf_fit,new_data = train,type="prob") %>% select(.pred_1)
test_pred=predict(final_rf_fit,new_data = test,type="prob") %>% select(.pred_1)
train.score=train_pred$.pred_1
real=train$Revenue.Grid
rocit = ROCit::rocit(score = train.score,
class = real)
kplot=ROCit::ksplot(rocit)
my_cutoff=kplot$`KS Cutoff`
test_hard_class=as.numeric(test_pred>my_cutoff)
model_explainer =explain_tidymodels(
final_rf_fit,
data = dplyr::select(train, -Revenue.Grid),
y = as.integer(train$Revenue.Grid),
verbose = FALSE
)
pdp = model_profile(
model_explainer,
variables = "family_income",
N = 2000,
groups='children'
)
plot(pdp)
library(tidymodels)
library(visdat)
library(tidyr)
library(car)
library(pROC)
library(ggplot2)
library(vip)
library(rpart.plot)
library(DALEXtra)
file=read.csv("D:\IITK Data Analytics\R\DecisionTrees-RandomForests-and-BoostingMachines\paydayloan_collections.csv",stringsAsFactors = FALSE)
file=read.csv("D:\\IITK Data Analytics\\R\\DecisionTrees-RandomForests-and-BoostingMachines\\paydayloan_collections.csv",stringsAsFactors = FALSE)
View(file)
vis_dat(file)
vis_dat(file,warn_large_data=False)
vis_dat(file,warn_large_data=F)
glimpse(file)
unique(file$var1)
unique(file$var2)
unique(file$var9
)
unique(file$var10)
unique(file$var11)
unique(file$var13)
unique(file$var17)
unique(file$var19)
unique(file$var23)
unique(file$var29)
unique(file$var3)
#target column to be treated seperately. Good practice
file$payment=as.factor(as.numeric(file$payment==1))
file$payment==1
file=read.csv("D:\\IITK Data Analytics\\R\\DecisionTrees-RandomForests-and-BoostingMachines\\paydayloan_collections.csv",stringsAsFactors = FALSE)
#target column to be treated seperately. Good practice
file$payment=as.factor(as.numeric(file$payment=='Success'))
dp_pipe=recipe(payment~.,data=file) %>%
#update_role(REF_NO,post_code,post_area,new_role = "drop_vars") %>%
update_role(var1,var2,var9,var10,var11,var13,var17,var19,var23,
var29,new_role="to_dummies") %>%
step_unknown(has_role("to_dummies"),new_level="__missing__") %>%
step_other(has_role("to_dummies"),threshold =0.02,other="__other__") %>%
step_dummy(has_role("to_dummies")) %>%
step_impute_median(all_numeric(),-all_outcomes())
dp_pipe=prep(dp_pipe)
train=bake(dp_pipe,new_data=NULL)
vis_dat(train)
vis_dat(train,warn_large_data=F)
file=bake(dp_pipe,new_data=NULL)
vis_dat(file,warn_large_data=F)
#splitting into train and test set
set.seed(2)
s=sample(1:nrow(file),0.7*nrow(file))
train=pdl[s,]
test=pdl[-s,]
train=file[s,]
test=file[-s,]
View(train)
#Decision Tree Model
tree_model=decision_tree(
cost_complexity = tune(),
tree_depth = tune(),
min_n = tune() #min number of obs in a node
) %>%
set_engine("rpart") %>% #package name rpart , show_engines("decision_tree")
set_mode("classification") #regression/classification
folds = vfold_cv(train, v = 5)
tree_grid = grid_regular(cost_complexity(), tree_depth(),   # run each ot these indvidually to get idea of range
min_n(), levels = 3) #select 3 best values for each of these
my_res=tune_grid(
tree_model,
payment~.,
resamples = folds,
grid = tree_grid,
metrics = metric_set(roc_auc), #rmse ,mae for regression
control = control_grid(verbose = TRUE)
)
autoplot(my_res)+theme_light() #roc higher the better
fold_metrics=collect_metrics(my_res)
my_res %>% show_best()
final_tree_fit=tree_model %>%
finalize_model(select_best(my_res)) %>%
fit(Revenue.Grid~.,data=train)
final_tree_fit=tree_model %>%
finalize_model(select_best(my_res)) %>%
fit(payment~.,data=train)
train_pred=predict(final_tree_fit,new_data = train,type="prob") %>% select(.pred_1)
test_pred=predict(final_tree_fit,new_data = test,type="prob") %>% select(.pred_1)
train.score=train_pred$.pred_1
real=train$payment
rocit = ROCit::rocit(score = train.score,
class = real)
kplot=ROCit::ksplot(rocit,legend=F)
my_cutoff=kplot$`KS Cutoff`
test_hard_class=as.numeric(test_pred>my_cutoff)
rocit
file=read.csv("D:\\IITK Data Analytics\\R\\DecisionTrees-RandomForests-and-BoostingMachines\\paydayloan_collections.csv",stringsAsFactors = FALSE)
pdl=read.csv("D:\\IITK Data Analytics\\R\\DecisionTrees-RandomForests-and-BoostingMachines\\paydayloan_collections.csv",stringsAsFactors = FALSE)
glimpse(pdl)
# data preparation
pdl=pdl %>%
mutate(payment=ifelse(payment=="Success",1,0))
pdl=pdl %>%
na.omit()
for(i in 1:31){
if(class(pdl[,i])=="character")
{
pdl[,i]=as.factor(pdl[,i])
}
}
pdl$payment=as.factor(pdl$payment)
set.seed(2)
s=sample(1:nrow(pdl),0.7*nrow(pdl))
pdl_train=pdl[s,]
pdl_test=pdl[-s,]
glimpse(pdl_train)
library(tree)
library(ISLR)
tree.pdl= tree(payment~.,data=pdl_train,na.action=na.exclude)
summary(tree.pdl)
tree.pred.test=predict(tree.pdl,newdata=pdl_test,type="class")
table(tree.pred.test,pdl_test$payment)
table(test_pred,test$payment)
kplot=ROCit::ksplot(rocit,legend=T)
test_hard_class=as.numeric(test_pred>my_cutoff)
?confusionMatrix
table(test_hard_class,test$payment)
# Random Forest Model
rf_model = rand_forest(
mtry = tune(),
trees = tune(),
min_n = tune()
) %>%
set_mode("classification") %>%
set_engine("ranger")
folds = vfold_cv(train, v = 5)
rf_grid = grid_regular(mtry(c(5,25)), trees(c(100,500)),
min_n(c(2,10)),levels = 3)
my_res=tune_grid(
rf_model,
payment~.,
resamples = folds,
grid = rf_grid,
metrics = metric_set(roc_auc),
control = control_grid(verbose = TRUE)
)
autoplot(my_res)+theme_light()
fold_metrics=collect_metrics(my_res)
my_res %>% show_best()
final_rf_fit=rf_model %>%
set_engine("ranger",importance='permutation') %>%
finalize_model(select_best(my_res,"roc_auc")) %>%
fit(payment~.,data=train)
final_rf_fit %>%
vip(geom = "col", aesthetics = list(fill = "midnightblue", alpha = 0.8)) +
scale_y_continuous(expand = c(0, 0))
train_pred=predict(final_rf_fit,new_data = train,type="prob") %>% select(.pred_1)
test_pred=predict(final_rf_fit,new_data = test,type="prob") %>% select(.pred_1)
train.score=train_pred$.pred_1
real=train$payment
rocit = ROCit::rocit(score = train.score,
class = real)
final_rf_fit %>%
vip(geom = "col", aesthetics = list(fill = "midnightblue", alpha = 0.8)) +
scale_y_continuous(expand = c(0, 0))
final_rf_fit=rf_model %>%
set_engine("ranger",importance='permutation') %>%
finalize_model(select_best(my_res,"roc_auc")) %>%
fit(payment~.,data=train)
final_rf_fit=rf_model %>%
set_engine("ranger",importance='permutation') %>%
finalize_model(select_best(my_res,"roc_auc")) %>%
fit(payment~.,data=train)
final_rf_fit %>%
vip(geom = "col", aesthetics = list(fill = "midnightblue", alpha = 0.8)) +
scale_y_continuous(expand = c(0, 0))
train_pred=predict(final_rf_fit,new_data = train,type="prob") %>% select(.pred_1)
test_pred=predict(final_rf_fit,new_data = test,type="prob") %>% select(.pred_1)
train.score=train_pred$.pred_1
real=train$payment
rocit = ROCit::rocit(score = train.score,
class = real)
kplot=ROCit::ksplot(rocit)
my_cutoff=kplot$`KS Cutoff`
test_hard_class=as.numeric(test_pred>my_cutoff)
table(test_hard_class,test$payment)
library(tidymodels)
library(visdat)
library(tidyr)
library(car)
library(pROC)
library(ggplot2)
library(vip)
library(rpart.plot)
library(DALEXtra)
library(dplyr)
setwd("D:\\IITK Data Analytics\\R\\MockProject-regression---classification\\")
train=read.csv("loan_data_train.csv",stringsAsFactors = F)
test=read.csv("loan_data_test.csv",stringsAsFactors = F)
glimpse(test)
test$Interest.Rate=NA
train$data='train' #creating placeholders
test$data='test'   #creating placeholders
df=rbind(train,test)
glimpse(df)
vis_dat(df)
#DATA PREP STARTS
df=df %>%
mutate(Debt.To.Income.Ratio=gsub("%","",Debt.To.Income.Ratio),
Interest.Rate=gsub("%","",Interest.Rate))
### reading the files-----------------------------------
setwd("D:\\IITK Data Analytics\\R\\REAL-ESTATE-R-PROJECT")
filetrain='housing_train.csv'
filetest='housing_test.csv'
train=read.csv(filetrain,stringsAsFactors = F)
test=read.csv(filetest,stringsAsFactors = F)
### studying the dataset-----------------------------
str(train)
glimpse(train)
vis_dat(train)
#### Part 2 starts -------------------------------------
test$Price=NA
train$data='train' #creating placeholders
test$data='test'   #creating placeholders
df=rbind(train,test)
glimpse(df)
vis_dat(df)
# Data Preparation--------------------------------------
#df = df %>% select(-Address) #dropping address
df$Price=as.numeric(df$Price) #treating response  column separately
unique(df$Postcode)
table(df$Postcode)
View(train)
View(train)
dp_pipe=recipe(Price~.,data=df) %>%
update_role(Address,YearBuilt,BuildingArea,new_role = "drop_vars") %>%
update_role(Suburb,Type,Method,SellerG,
CouncilArea,Postcode ,new_role="to_dummies") %>%
step_rm(has_role("drop_vars")) %>%
step_unknown(has_role("to_dummies"),new_level="__missing__") %>%
step_other(has_role("to_dummies"),threshold =0.03,other="__other__") %>%
step_dummy(has_role("to_dummies")) %>%
step_impute_median(all_numeric(),-all_outcomes())
dp_pipe=prep(dp_pipe)
prep_df=bake(dp_pipe,new_data=NULL)
vis_dat(prep_df) #all looks good!
prep_df=bake(dp_pipe,new_data=NULL)
dp_pipe=prep(dp_pipe)
df$Postcode=as.factor(df$Postcode) #treating postcode as category
dp_pipe=recipe(Price~.,data=df) %>%
update_role(Address,YearBuilt,BuildingArea,new_role = "drop_vars") %>%
update_role(Suburb,Type,Method,SellerG,
CouncilArea,Postcode ,new_role="to_dummies") %>%
step_rm(has_role("drop_vars")) %>%
step_unknown(has_role("to_dummies"),new_level="__missing__") %>%
step_other(has_role("to_dummies"),threshold =0.03,other="__other__") %>%
step_dummy(has_role("to_dummies")) %>%
step_impute_median(all_numeric(),-all_outcomes())
dp_pipe=prep(dp_pipe)
prep_df=bake(dp_pipe,new_data=NULL)
vis_dat(prep_df) #all looks good!
#dropping NA response rows in training set
prep_df=prep_df[!((is.na(prep_df$Price)) & prep_df$data=='train'), ]
#separating train and test dataset---------------------------
train=prep_df %>% filter(data=='train') %>% select(-data,-Type_X__other__)
test=prep_df %>% filter(data=='test') %>% select(-data,-Price,-Type_X__other__)
vis_dat(train)
vis_dat(test)
for_vif=lm(Price~.,data=train)
sort(vif(for_vif),decreasing = T)[1:3]
View(train)
View(train)
# Data Preparation--------------------------------------
#df = df %>% select(-Address) #dropping address
df$Price=as.numeric(df$Price) #treating response  column separately
df$Postcode=as.factor(df$Postcode) #treating postcode as category
dp_pipe=recipe(Price~.,data=df) %>%
update_role(Address,YearBuilt,BuildingArea,,Postcode,new_role = "drop_vars") %>%
update_role(Suburb,Type,Method,SellerG,
CouncilArea ,new_role="to_dummies") %>%
step_rm(has_role("drop_vars")) %>%
step_unknown(has_role("to_dummies"),new_level="__missing__") %>%
step_other(has_role("to_dummies"),threshold =0.03,other="__other__") %>%
step_dummy(has_role("to_dummies")) %>%
step_impute_median(all_numeric(),-all_outcomes())
dp_pipe=recipe(Price~.,data=df) %>%
update_role(Address,YearBuilt,BuildingArea,Postcode,new_role = "drop_vars") %>%
update_role(Suburb,Type,Method,SellerG,
CouncilArea ,new_role="to_dummies") %>%
step_rm(has_role("drop_vars")) %>%
step_unknown(has_role("to_dummies"),new_level="__missing__") %>%
step_other(has_role("to_dummies"),threshold =0.03,other="__other__") %>%
step_dummy(has_role("to_dummies")) %>%
step_impute_median(all_numeric(),-all_outcomes())
dp_pipe=prep(dp_pipe)
prep_df=bake(dp_pipe,new_data=NULL)
vis_dat(prep_df) #all looks good!
#dropping NA response rows in training set
prep_df=prep_df[!((is.na(prep_df$Price)) & prep_df$data=='train'), ]
#separating train and test dataset---------------------------
train=prep_df %>% filter(data=='train') %>% select(-data,-Type_X__other__)
test=prep_df %>% filter(data=='test') %>% select(-data,-Price,-Type_X__other__)
vis_dat(train)
vis_dat(test)
for_vif=lm(Price~.,data=train)
sort(vif(for_vif),decreasing = T)[1:3]
# Data Preparation--------------------------------------
#df = df %>% select(-Address) #dropping address
df$Price=as.numeric(df$Price) #treating response  column separately
df$Postcode=as.factor(df$Postcode) #treating postcode as category
dp_pipe=recipe(Price~.,data=df) %>%
update_role(Address,Postcode,new_role = "drop_vars") %>%
update_role(Suburb,Type,Method,SellerG,
CouncilArea ,new_role="to_dummies") %>%
step_rm(has_role("drop_vars")) %>%
step_unknown(has_role("to_dummies"),new_level="__missing__") %>%
step_other(has_role("to_dummies"),threshold =0.03,other="__other__") %>%
step_dummy(has_role("to_dummies")) %>%
step_impute_median(all_numeric(),-all_outcomes())
dp_pipe=prep(dp_pipe)
prep_df=bake(dp_pipe,new_data=NULL)
vis_dat(prep_df) #all looks good!
#dropping NA response rows in training set
prep_df=prep_df[!((is.na(prep_df$Price)) & prep_df$data=='train'), ]
#separating train and test dataset---------------------------
train=prep_df %>% filter(data=='train') %>% select(-data,-Type_X__other__)
test=prep_df %>% filter(data=='test') %>% select(-data,-Price,-Type_X__other__)
vis_dat(train)
vis_dat(test)
for_vif=lm(Price~.,data=train)
sort(vif(for_vif),decreasing = T)[1:3]
rm(for_vif)
fit=lm(Price~.,data=train)
fit=stats::step(fit)
summary(fit)
fit=lm(formula = Price ~ Rooms + Distance + Bedroom2 + Bathroom +
Car + Landsize + BuildingArea + YearBuilt + Suburb_X__other__ +
Type_t + Type_u + Method_S +
SellerG_Buxton + SellerG_Jellis + SellerG_Marshall + SellerG_X__other__ +
CouncilArea_Banyule + CouncilArea_Bayside + CouncilArea_Boroondara +
CouncilArea_Darebin + CouncilArea_Hobsons.Bay + CouncilArea_Maribyrnong +
CouncilArea_Melbourne + CouncilArea_Moonee.Valley + CouncilArea_Moreland +
CouncilArea_Port.Phillip + CouncilArea_Yarra +
CouncilArea_X__other__, data = train)
#PREDICTION
test.predictions=predict(fit,newdata=test)
write.csv(test.predictions,'SimpleLinearRegression.csv',row.names = F)
plot(fit,1) # residual vs fitted values => non-linearity in the data exists or not
plot(fit,2) # errors are normal or not
plot(fit,3) # variance is constant or not
plot(fit,4) # outliers in the data if cook's distance >1
